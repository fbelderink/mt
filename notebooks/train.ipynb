{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/SsC9pQbzN1iQUwOiauDY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "EbRZLZB7_wt6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content\n",
        "!rm -rf /content/mt"
      ],
      "metadata": {
        "id": "qRm_KULVSc9E",
        "outputId": "63031836-fe0f-4682-851a-37747523f40b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "chdir: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone if does not exist\n",
        "if not os.path.isdir('/content/mt'):\n",
        "    !git clone https://github.com/fbelderink/mt.git\n",
        "%cd /content/mt\n",
        "!git pull\n",
        "!git checkout fb/dev\n",
        "!git pull"
      ],
      "metadata": {
        "id": "bP_4kOLwQlUL",
        "outputId": "68eb2a46-1d6e-4fd1-e1f1-cfacc79a38cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "fatal: could not create work tree dir 'mt': No such file or directory\n",
            "[Errno 2] No such file or directory: '/content/mt'\n",
            "/content/mt\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "fatal: Unable to read current working directory: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "fatal: Unable to read current working directory: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "fatal: Unable to read current working directory: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import training.train as train\n",
        "from utils.ConfigLoader import ConfigLoader\n",
        "from utils.hyperparameters import Hyperparameters\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "MHuWvjXRQpop"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bBQa3KOv9PnM",
        "outputId": "a4f81938-b8f2-4b78-ec04-7a6197f4a4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "training on cuda:0\n",
            "Number of Batches: 2094\n",
            "Batch Size: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of trainable parameters: 48375765\n",
            "Layers:\n",
            "source_embedding: Embedding(6797, 200)\n",
            "target_embedding: Embedding(6461, 200)\n",
            "fc_source: Linear(in_features=1000, out_features=300, bias=True)\n",
            "fc_source_bn: BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "fc_target: Linear(in_features=400, out_features=300, bias=True)\n",
            "fc_target_bn: BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "fc1: Linear(in_features=600, out_features=500, bias=True)\n",
            "fc1_bn: BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "fc2: Linear(in_features=500, out_features=6461, bias=True)\n",
            "fc2_bn: BatchNorm1d(6461, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "output_layer: Linear(in_features=6461, out_features=6461, bias=True)\n",
            "\n",
            "        Starting Training: \n",
            "\n",
            "batch_accuracy:0.23\n",
            "batch_perplexity:306.8534851074219\n",
            "epoch: 0\n",
            "steps: 10\n",
            "\n",
            "batch_accuracy:0.355\n",
            "batch_perplexity:108.71749114990234\n",
            "epoch: 0\n",
            "steps: 20\n",
            "\n",
            "batch_accuracy:0.305\n",
            "batch_perplexity:130.63746643066406\n",
            "epoch: 0\n",
            "steps: 30\n",
            "\n",
            "batch_accuracy:0.335\n",
            "batch_perplexity:115.86383819580078\n",
            "epoch: 0\n",
            "steps: 40\n",
            "\n",
            "batch_accuracy:0.435\n",
            "batch_perplexity:71.20741271972656\n",
            "epoch: 0\n",
            "steps: 50\n",
            "\n",
            "batch_accuracy:0.3\n",
            "batch_perplexity:93.36865997314453\n",
            "epoch: 0\n",
            "steps: 60\n",
            "\n",
            "batch_accuracy:0.41\n",
            "batch_perplexity:60.08137130737305\n",
            "epoch: 0\n",
            "steps: 70\n",
            "\n",
            "batch_accuracy:0.36\n",
            "batch_perplexity:97.75074005126953\n",
            "epoch: 0\n",
            "steps: 80\n",
            "\n",
            "batch_accuracy:0.37\n",
            "batch_perplexity:60.9271125793457\n",
            "epoch: 0\n",
            "steps: 90\n",
            "\n",
            "batch_accuracy:0.315\n",
            "batch_perplexity:100.77994537353516\n",
            "epoch: 0\n",
            "steps: 100\n",
            "\n",
            "batch_accuracy:0.39\n",
            "batch_perplexity:65.09942626953125\n",
            "epoch: 0\n",
            "steps: 110\n",
            "\n",
            "batch_accuracy:0.345\n",
            "batch_perplexity:85.21687316894531\n",
            "epoch: 0\n",
            "steps: 120\n",
            "\n",
            "batch_accuracy:0.43\n",
            "batch_perplexity:56.37656021118164\n",
            "epoch: 0\n",
            "steps: 130\n",
            "\n",
            "batch_accuracy:0.395\n",
            "batch_perplexity:70.49332427978516\n",
            "epoch: 0\n",
            "steps: 140\n",
            "\n",
            "batch_accuracy:0.435\n",
            "batch_perplexity:37.92090606689453\n",
            "epoch: 0\n",
            "steps: 150\n",
            "\n",
            "batch_accuracy:0.44\n",
            "batch_perplexity:41.804115295410156\n",
            "epoch: 0\n",
            "steps: 160\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-e5a174ef05a6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     ConfigLoader(\"configs/config.yaml\").get_config())\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m train.train(os.path.join(dataset_dir,\n\u001b[0m\u001b[1;32m     10\u001b[0m                         f\"train7k_w{model_hyperparameters.window_size}.pt\"),\n\u001b[1;32m     11\u001b[0m             os.path.join(dataset_dir,\n",
            "\u001b[0;32m/content/mt/training/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_path, validation_path, config, max_epochs, shuffle, num_workers, val_rate, train_eval_rate)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# print batch metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mbatch_correct_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_correct_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mtrue_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_correct_predictions\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrue_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mt/training/train.py\u001b[0m in \u001b[0;36m_count_correct_predictions\u001b[0;34m(pred, L)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "drive_dir = '/content/drive'\n",
        "drive.mount(drive_dir)\n",
        "\n",
        "dataset_dir = os.path.join(drive_dir,'MyDrive/data/mt')\n",
        "\n",
        "model_hyperparameters = Hyperparameters(\n",
        "    ConfigLoader(\"configs/config.yaml\").get_config())\n",
        "\n",
        "train.train(os.path.join(dataset_dir,\n",
        "                        f\"train7k_w{model_hyperparameters.window_size}.pt\"),\n",
        "            os.path.join(dataset_dir,\n",
        "                        f\"val7k_w{model_hyperparameters.window_size}.pt\"),\n",
        "            model_hyperparameters,\n",
        "            val_rate=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "date = datetime.today().strftime('%d-%m-%Y')"
      ],
      "metadata": {
        "id": "s8hT1NbQFvuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r {dataset_dir}/checkpoints.zip eval/checkpoints/{date}/"
      ],
      "metadata": {
        "id": "iNigHQytLeRS",
        "outputId": "6ebbb523-1a9f-47fa-d192-5905d8c78acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: eval/checkpoints/12-06-2024/ (stored 0%)\n",
            "updating: eval/checkpoints/12-06-2024/20_13_43.pth\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from assignments.assignment4 import *\n",
        "from utils.file_manipulation import load_data\n",
        "from preprocessing.dictionary import Dictionary\n",
        "\n",
        "data_de = load_data(\"data/raw/multi30k.dev.de\")\n",
        "data_en = load_data(\"data/raw/multi30k.dev.en\")\n",
        "\n",
        "dict_de = Dictionary.load(os.path.join(dataset_dir, \"dicts/train_dict_de_w2.pkl\"))\n",
        "dict_en = Dictionary.load(os.path.join(dataset_dir, \"dicts/train_dict_en_w2.pkl\"))\n",
        "\n",
        "model = torch.load(f\"eval/checkpoints/{date}/20_12_53.pth\")\n",
        "\n",
        "test_model_bleu(model, data_de, data_en, dict_de, dict_en,\n",
        "                3, model_hyperparameters.window_size, True, None)"
      ],
      "metadata": {
        "id": "KBi_wD3fHwbR",
        "outputId": "79557fd7-4b4b-4183-8350-14520191149b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-b6668b4a1d44>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"eval/checkpoints/{date}/20_12_53.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m test_model_bleu(model, data_de, data_en, dict_de, dict_en,\n\u001b[0m\u001b[1;32m     15\u001b[0m                 3, model_hyperparameters.window_size, True, None)\n",
            "\u001b[0;32m/content/mt/assignments/assignment4.py\u001b[0m in \u001b[0;36mtest_model_bleu\u001b[0;34m(model, source_data, reference_data, source_dict, target_dict, beam_size, window_size, do_beam_search, translations)\u001b[0m\n\u001b[1;32m     45\u001b[0m                     do_beam_search, translations: List[List[str]]):\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     bleu_score = get_bleu_of_model(model, source_data, reference_data, source_dict, target_dict, beam_size, window_size,\n\u001b[0m\u001b[1;32m     48\u001b[0m                                    do_beam_search, translations)\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model BLEU: {bleu_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mt/metrics/calculate_bleu_of_model.py\u001b[0m in \u001b[0;36mget_bleu_of_model\u001b[0;34m(model, source_data, reference_data, source_dict, target_dict, beam_size, window_size, do_beam_search, translations)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_beam_search\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtranslations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedy_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mt/search/beam_search.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(model, source_data, source_dict, target_dict, beam_size, window_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msource_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_vocabulary_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_performed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mget_target_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index_of_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mt/preprocessing/dictionary.py\u001b[0m in \u001b[0;36mapply_vocabulary_to_text\u001b[0;34m(self, data, bpe_performed)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                  bpe_performed=False) -> List[List[str]]:\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbpe_performed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperform_bpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mt/preprocessing/BPE.py\u001b[0m in \u001b[0;36mperform_bpe\u001b[0;34m(data, operations)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;31m# apply all operations to word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0msplit_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mtransformed_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}